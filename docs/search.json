[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "censo2022-domicilios",
    "section": "",
    "text": "Este projeto processa e analisa os microdados do Censo Demogr√°fico 2022.\n\n\n\n\nExecute o pipeline de importa√ß√£o: 01-import-data.qmd\nOs dados ser√£o processados e organizados automaticamente\n\n\n\n\n\n01-import-data.qmd - Pipeline completo de download e convers√£o\ndata/ - Dados brutos e processados\ndocs/ - Site gerado (GitHub Pages)"
  },
  {
    "objectID": "index.html#dados-de-domic√≠lios",
    "href": "index.html#dados-de-domic√≠lios",
    "title": "censo2022-domicilios",
    "section": "",
    "text": "Este projeto processa e analisa os microdados do Censo Demogr√°fico 2022.\n\n\n\n\nExecute o pipeline de importa√ß√£o: 01-import-data.qmd\nOs dados ser√£o processados e organizados automaticamente\n\n\n\n\n\n01-import-data.qmd - Pipeline completo de download e convers√£o\ndata/ - Dados brutos e processados\ndocs/ - Site gerado (GitHub Pages)"
  },
  {
    "objectID": "01-import-data.html",
    "href": "01-import-data.html",
    "title": "Import Data",
    "section": "",
    "text": "Sobre\nEste script apresenta um pipeline reproduz√≠vel para baixar, organizar, padronizar e consolidar os dados agregados referentes √† dados de Domic√≠los do Universo do Censo Demogr√°fico 2022 produzidos pelo Instituto Brasileiro de Geografia e Estat√≠stica - IBGE.\nO objetivo √© transformar os arquivos originais, distribu√≠dos em m√∫ltiplos conjuntos tem√°ticos e arquivos CSV, em um conjunto integrado, limpo e eficiente de bases no formato parquet:\n\n01_basico.parquet\n02_domicilio.parquet\n\n\n\nBibliotecas\nLoad Packages\n\nlibrary(arrow)\nlibrary(dplyr)\nlibrary(fs)\nlibrary(here)\nlibrary(httr)\nlibrary(janitor)\nlibrary(purrr)\nlibrary(readr)\nlibrary(rvest)\nlibrary(stringr)\n\n\n\nConfigura√ß√£o do ambiente\nSet the Environment\n\n# Defini√ß√£o da estrutura de pastas para organizar os dados \npasta_base &lt;- here(\"data\") \n\npastas &lt;- c(\n  sprintf(\"%s/logs\", pasta_base),\n  sprintf(\"%s/raw\", pasta_base),\n  sprintf(\"%s/processed\", pasta_base)\n)\n\n# Criar pastas se ainda n√£o existirem\nfor (pasta in pastas) {\n  dir.create(pasta, recursive = TRUE, showWarnings = FALSE)\n}\n\n# Atribuir nomes √†s vari√°veis \npasta_logs &lt;- pastas[1]  # Erros, arquivos de log\npasta_arqs &lt;- pastas[2]  # Dados brutos (zips baixados e csvs descompactados)\npasta_pqs  &lt;- pastas[3]  # Dados processados (parquets e csvs tem√°ticos)\n# teste teste\n\nAumentar o tempo m√°ximo permitido para downloads:\n(padr√£o do R = 60s; arquivos do Censo s√£o grandes e podem demorar mais)\n\n# getOption(\"timeout\") # Descomente para verificar o valor atual options\n(timeout = 1000) # Define novo limite (em segundos, aprox. 16 min)\n\n\n\n1. Baixar e descompactar os dados brutos\nImport\n\n1.1 Defini√ß√£o do link de download\nO IBGE disponibiliza os agregados por setor censit√°rio em duas vers√µes:\n\nXLSX: menor, mas mais lenta para carregar\nCSV: maior, por√©m mais leve para importar no R\n\nOptamos pela vers√£o CSV.\n\nurl &lt;- \"https://ftp.ibge.gov.br/Censos/Censo_Demografico_2022/Agregados_por_Setores_Censitarios/Agregados_por_Setor_csv/\"\n\n\n\n1.2 Listagem dos arquivos dispon√≠veis\n\n\n [1] \"Agregados_por_setores_alfabetizacao_BR.zip\"                      \n [2] \"Agregados_por_setores_basico_BR_20250417.zip\"                    \n [3] \"Agregados_por_setores_caracteristicas_domicilio1_BR.zip\"         \n [4] \"Agregados_por_setores_caracteristicas_domicilio2_BR_20250417.zip\"\n [5] \"Agregados_por_setores_caracteristicas_domicilio3_BR_20250417.zip\"\n [6] \"Agregados_por_setores_cor_ou_raca_BR.zip\"                        \n [7] \"Agregados_por_setores_demografia_BR.zip\"                         \n [8] \"Agregados_por_setores_domicilios_indigenas_BR.zip\"               \n [9] \"Agregados_por_setores_domicilios_quilombolas_BR.zip\"             \n[10] \"Agregados_por_setores_obitos_BR.zip\"                             \n[11] \"Agregados_por_setores_parentesco_BR.zip\"                         \n[12] \"Agregados_por_setores_pessoas_indigenas_BR.zip\"                  \n[13] \"Agregados_por_setores_pessoas_quilombolas_BR.zip\"                \n\n\nVamos selecionar apenas os arquivos ‚ÄúB√°sico‚Äù e aqueles com dados de Domic√≠lios.\n\n\n[1] \"Agregados_por_setores_basico_BR_20250417.zip\"                    \n[2] \"Agregados_por_setores_caracteristicas_domicilio1_BR.zip\"         \n[3] \"Agregados_por_setores_caracteristicas_domicilio2_BR_20250417.zip\"\n[4] \"Agregados_por_setores_caracteristicas_domicilio3_BR_20250417.zip\"\n[5] \"Agregados_por_setores_domicilios_indigenas_BR.zip\"               \n[6] \"Agregados_por_setores_domicilios_quilombolas_BR.zip\"             \n\n\n\n\n1.3 Obter o tamanho dos arquivos a serem baixados\n\n\n179M\n\n\n\n\n1.4 Download dos arquivos\nBaixar os arquivos zips, se ainda n√£o existirem, e salv√°-los na pasta ‚Äúraw‚Äù.\n\nwalk(urls, function(url) {\n  arquivo_local &lt;- file.path(pasta_arqs, basename(url))\n  \n  if (!file_exists(arquivo_local)) {\n    size_esperado &lt;- get_file_size(url)\n    resultado &lt;- try(download.file(url, arquivo_local, quiet = TRUE), silent = TRUE)\n    \n    if (inherits(resultado, \"try-error\") || \n        !file_exists(arquivo_local) || \n        (size_esperado &gt; 0 && file_size(arquivo_local) != size_esperado)) {\n      \n      cat(\"Erro no download:\", basename(url), \"\\n\")\n      \n      # Registro no log se tiver erro\n      download_error &lt;- data.frame(\n        arquivo = basename(url),\n        tipo    = \"universo_zip\",\n        stringsAsFactors = FALSE\n      )\n      \n      out_file &lt;- file.path(pasta_logs, \"erros_download_arqs.csv\")\n      write_delim(download_error, out_file, delim = \";\",\n                  append = file_exists(out_file))\n      \n      if (file_exists(arquivo_local)) file_delete(arquivo_local)\n      return()\n    }\n    cat(\"Download conclu√≠do:\", basename(url), \"\\n\")\n  } else {\n    cat(\"Arquivo j√° existe na pasta:\", basename(url), \"\\n\")\n  }\n})\n\n\n\n1.5 Descompactar os arquivos\nDescompactar os arquivos em formato .zip vai gerar os arquivos em .csv. O resultado √© salvo na pasta ‚Äúprocessed‚Äù.\n\nzip_files &lt;- pasta_arqs |&gt; \n        dir_ls(type = \"file\", regexp = \"\\\\.zip$\")\ncsv_files &lt;- pasta_arqs |&gt; \n        dir_ls(type = \"file\", regexp = \"\\\\.csv$\")\n\n# Se a pasta CSV j√° tem arquivos, pula o unzip\nif (length(csv_files) == 0) {\n  zip_files |&gt; \n        map(\\(x) unzip(x, exdir = pasta_arqs), .progress = TRUE)\n} else {\n  cat(\"Arquivos CSV j√° descompactados, pulando unzip...\\n\")\n}\nzip_files |&gt; file_delete() \n\n\n\n\n2. Leitura e tratamento dos dados\nTidy\nNesta etapa, os arquivos CSV descompactados s√£o lidos, padronizados e organizados em estruturas consistentes para posterior integra√ß√£o.\n\n2.1 Criar fun√ß√£o para leitura dos arquivos\nO trecho define a fun√ß√£o abrir_csv(), que localiza todos os arquivos CSV em uma pasta usando um padr√£o (reg_pattern), l√™ todos eles como texto, concatena em um √∫nico data frame, padroniza nomes de colunas, converte para num√©ricas as vari√°veis de resultado (VXXXX), ordena pela primeira coluna (geralmente cd_setor) e devolve um objeto limpo e pronto para an√°lise. A cada etapa, arqs_csv √© atualizado, sempre substituindo o conte√∫do anterior pelo novo.\n\nabrir_csv &lt;- function(reg_pattern) {\n# Localizar arquivos CSV que correspondem ao padr√£o informado (\"reg_pattern\")\n    arqs_csv &lt;- list.files(pasta_arqs,\n                         pattern = reg_pattern,\n                         full.names = TRUE,\n                         recursive = FALSE)   \n# Ler os CSVs como texto e transformar em df\n  arqs_csv &lt;- read_delim(arqs_csv,\n                         delim = \";\",\n                         col_types = cols(.default = \"c\"),\n                         locale = locale(encoding = \"iso_8859-1\")) %&gt;%\n    arrange(.[[1]]) # ordenar pela primeira coluna (cd_setor)\n  \n# Padroniza√ß√£o (nomes snake_case, vari√°veis Vxxxx para mai√∫sculas (padr√£o oficial do IBGE)\n  arqs_csv &lt;- arqs_csv %&gt;%\n    clean_names() %&gt;%\n    rename_at(vars(matches(\"^v[0-9]{4}[0-9]?$\")), toupper) |&gt;\n    rename(cd_setor = any_of(\"setor\"))\n  \n# Tratamento especial para o arquivo \"basico\" \n  if (str_detect(reg_pattern, \"basico\")) {\n      arqs_csv &lt;- arqs_csv %&gt;%\n      mutate_at(vars\n                (matches(\"V[0-9]{3}[0-9]?$\")), \n                ~ str_replace(., ',', '.')) %&gt;%\n      mutate(area_km2 = str_replace(area_km2, ',', '.'))\n      \n    # extrair lista √∫nica de setores para uso nos parquets tem√°ticos\n    setores &lt;- arqs_csv %&gt;% \n      select(cd_setor) %&gt;% \n      distinct()\n\n    out_file &lt;- sprintf(\"%s/00_setores.csv\", pasta_pqs) \n    write_delim(setores, out_file, delim = ';')\n  }\n  \n# Transformar valores que significam \"aus√™ncia de dado\" (X, x, . ‚Üí NA)\n  arqs_csv &lt;- arqs_csv %&gt;%\n    mutate(\n        across(everything(), \n               ~ str_replace(., \"^[Xx\\\\.]$\", \n                             as.character(NA))))\n  \n# Todas as vari√°veis Vxxxx para num√©ricas\n  arqs_csv &lt;- arqs_csv %&gt;% \n    mutate_at(vars\n              (matches(\"^V[0-9]{4}[0-9]?$\")), \n              as.numeric)\n  \n  return(arqs_csv)\n}\n\n\n\n2.2 Criar fun√ß√£o para agrupamento de arquivos tem√°ticos\n\njuntar_temas &lt;- function(pattern_list, cod_setores) {\n  # Dataframe para agregar resultados\n  df &lt;- cod_setores\n  # para cada padr√£o, abrir o CSV e juntar ao df\n  for (pat in pattern_list) {\n      tmp_df &lt;- abrir_csv(pat)\n      df &lt;- left_join(df, tmp_df, by = \"cd_setor\")\n  }\n# reordenar: cd_setor primeiro, depois em ordem alfab√©tica\n  outras &lt;- setdiff(names(df), \"cd_setor\")\n  df &lt;- df[, c(\"cd_setor\", sort(outras))]\n    \n  return(df)\n}\n\n\n\n\n3. Transformar os arquivos csvs em parquets\nTransform\nTemas: B√°sico e Domic√≠lios\nPara cada grupo, faz a mesma sequ√™ncia:\n\nL√™ os arquivos do grupo\nUsando a primeira fun√ß√£o criada abrir_csv(\"tema\")\nOrganiza os dados por setor censit√°rio\nUsando a segunda fun√ß√£o criada juntar_temas().\nExporta para .parquet\nUm formato mais leve e r√°pido que CSV. Arquivos salvos na pasta 03_processado.\nRemove objetos da mem√≥ria (rm e gc),\nNecess√°rio porque arquivos s√£o enormes.\n\n\n3.1 B√°sico\n\n# B√°sico\nif (!file_exists(sprintf(\"%s/01_basico.parquet\", pasta_pqs))) {\n  basico &lt;- abrir_csv(\"basico\")\n  basico &lt;- basico %&gt;% mutate(area_km2 = as.double(area_km2))\n  write_parquet(basico, sprintf(\"%s/01_basico.parquet\", pasta_pqs))\n  rm(basico); gc(T)\n  cat(\"01_basico.parquet criado\\n\")\n} else {\n  cat(\"01_basico.parquet j√° existe, pulando...\\n\")\n}\n\n01_basico.parquet j√° existe, pulando...\n\n\n\n# Exportar csv com todos os setores censit√°rios para uso nos temas a seguir\nsetores &lt;- sprintf(\"%s/00_setores.csv\", pasta_pqs)\n\nif (file_exists(setores)) {\n  setores &lt;- read_delim(setores, delim = \";\", col_types = \"c\")\n  cat(paste0(\"CSV com setores censit√°rios carregado (\", nrow(setores), \" setores)\\n\"))\n} else {\n  stop(\"00_setores.csv nao encontrado. Execute primeiro o bloco basico.\")\n}\n\nCSV com setores censit√°rios carregado (468099 setores)\n\n\n\n\n3.2 Domic√≠lios\nJun√ß√£o dos cinco arquivos que cont√©m informa√ß√µes sobre os domic√≠lios.\n\n# Domicilios\nif (!file_exists(sprintf(\"%s/02_domicilio.parquet\", pasta_pqs))) {\n\n  dom_patterns &lt;- list.files(\n    pasta_arqs,\n    pattern = \"domicilio.*\\\\.csv$\",\n    full.names = FALSE\n  ) |&gt;\n    \n    str_remove(\"^Agregados_por_setores_\") |&gt;\n    str_remove(\"_BR.*\\\\.csv$\")\n\n  dom &lt;- juntar_temas(dom_patterns, cod_setores = setores)\n\n  write_parquet(dom, sprintf(\"%s/02_domicilio.parquet\", pasta_pqs))\n\n  rm(dom); gc(TRUE)\n  cat(\"02_domicilio.parquet criado\\n\")\n\n} else {\n  cat(\"02_domicilio.parquet j√° existe, pulando...\\n\")\n}\n\n02_domicilio.parquet j√° existe, pulando...\n\n\n\n\n\n4. Explorar e validar os dados\nUnderstand\n\n# Resumo dos parquets finais\npqs_files &lt;- dir_ls(pasta_pqs, regexp = \"\\\\.parquet$\")\npqs_info &lt;- map_dfr(pqs_files, ~ {\n  df &lt;- read_parquet(.x)\n  tibble(\n    arquivo = basename(.x),\n    n_setores = nrow(df), # n√∫mero de setores censit√°rios\n    n_vars = ncol(df), # n√∫mero de colunas \n    tamanho_mb = file_size(.x),\n    memoria_mb = round(object.size(df) / 1024^2, 1)\n  )\n})\nprint(pqs_info)\n\n# A tibble: 2 √ó 5\n  arquivo              n_setores n_vars  tamanho_mb memoria_mb  \n  &lt;chr&gt;                    &lt;int&gt;  &lt;int&gt; &lt;fs::bytes&gt; &lt;objct_sz&gt;  \n1 01_basico.parquet       468099     36       11.9M 167 bytes   \n2 02_domicilio.parquet    468099   1030      144.1M 3707.1 bytes\n\n\n\nVis√£o geral do parquet b√°sico\n\npqs_files |&gt; \n  keep(~ str_detect(basename(.x), \"^01_\")) |&gt;  \n  walk(~ {\n    cat(\"\\n====\", basename(.x), \"====\\n\")\n    read_parquet(.x) |&gt; \n      slice_head(n = 5) |&gt; \n      select(cd_setor, everything()) |&gt;  \n      print(n = 6)  \n  })\n\n\n==== 01_basico.parquet ====\n# A tibble: 5 √ó 36\n  cd_setor      situacao cd_sit cd_tipo area_km2 cd_regiao nm_regiao cd_uf nm_uf\n  &lt;chr&gt;         &lt;chr&gt;    &lt;chr&gt;  &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt;\n1 110001505000‚Ä¶ Urbana   1      0          0.539 1         Norte     11    Rond‚Ä¶\n2 110001505000‚Ä¶ Urbana   1      0          0.236 1         Norte     11    Rond‚Ä¶\n3 110001505000‚Ä¶ Urbana   1      0          0.212 1         Norte     11    Rond‚Ä¶\n4 110001505000‚Ä¶ Urbana   1      0          0.505 1         Norte     11    Rond‚Ä¶\n5 110001505000‚Ä¶ Urbana   1      0          0.299 1         Norte     11    Rond‚Ä¶\n# ‚Ñπ 27 more variables: cd_mun &lt;chr&gt;, nm_mun &lt;chr&gt;, cd_dist &lt;chr&gt;,\n#   nm_dist &lt;chr&gt;, cd_subdist &lt;chr&gt;, nm_subdist &lt;chr&gt;, cd_bairro &lt;chr&gt;,\n#   nm_bairro &lt;chr&gt;, cd_nu &lt;chr&gt;, nm_nu &lt;chr&gt;, cd_fcu &lt;chr&gt;, nm_fcu &lt;chr&gt;,\n#   cd_aglom &lt;chr&gt;, nm_aglom &lt;chr&gt;, cd_rgint &lt;chr&gt;, nm_rgint &lt;chr&gt;,\n#   cd_rgi &lt;chr&gt;, nm_rgi &lt;chr&gt;, cd_concurb &lt;chr&gt;, nm_concurb &lt;chr&gt;,\n#   V0001 &lt;dbl&gt;, V0002 &lt;dbl&gt;, V0003 &lt;dbl&gt;, V0004 &lt;dbl&gt;, V0005 &lt;dbl&gt;,\n#   V0006 &lt;dbl&gt;, V0007 &lt;dbl&gt;\n\n\n\n\nVis√£o geral do parquet domic√≠lios\n\npqs_files |&gt; \n  keep(~ str_detect(basename(.x), \"^02_\")) |&gt;  \n  walk(~ {\n    cat(\"\\n====\", basename(.x), \"====\\n\")\n    read_parquet(.x) |&gt; \n      slice_head(n = 5) |&gt; \n      select(cd_setor, everything()) |&gt;  \n      print(n = 6)  \n  })\n\n\n==== 02_domicilio.parquet ====\n# A tibble: 5 √ó 1,030\n  cd_setor V00001 V00002 V00003 V00004 V00005 V00006 V00007 V00008 V00009 V00010\n  &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 1100015‚Ä¶    336      0      0    336    928      0      0    136      0      0\n2 1100015‚Ä¶    208      0      0    208    556      0      0     73      0      0\n3 1100015‚Ä¶     85      0      0     85    222      0      0     24      0      0\n4 1100015‚Ä¶    281     NA      0    281    783     NA      0    124      0      0\n5 1100015‚Ä¶    291      0      0    291    748      0      0    102      0      0\n# ‚Ñπ 1,019 more variables: V00011 &lt;dbl&gt;, V00012 &lt;dbl&gt;, V00013 &lt;dbl&gt;,\n#   V00014 &lt;dbl&gt;, V00015 &lt;dbl&gt;, V00016 &lt;dbl&gt;, V00017 &lt;dbl&gt;, V00018 &lt;dbl&gt;,\n#   V00019 &lt;dbl&gt;, V00020 &lt;dbl&gt;, V00021 &lt;dbl&gt;, V00022 &lt;dbl&gt;, V00023 &lt;dbl&gt;,\n#   V00024 &lt;dbl&gt;, V00025 &lt;dbl&gt;, V00026 &lt;dbl&gt;, V00027 &lt;dbl&gt;, V00028 &lt;dbl&gt;,\n#   V00029 &lt;dbl&gt;, V00030 &lt;dbl&gt;, V00031 &lt;dbl&gt;, V00032 &lt;dbl&gt;, V00033 &lt;dbl&gt;,\n#   V00034 &lt;dbl&gt;, V00035 &lt;dbl&gt;, V00036 &lt;dbl&gt;, V00037 &lt;dbl&gt;, V00038 &lt;dbl&gt;,\n#   V00039 &lt;dbl&gt;, V00040 &lt;dbl&gt;, V00041 &lt;dbl&gt;, V00042 &lt;dbl&gt;, V00043 &lt;dbl&gt;, ‚Ä¶"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "about",
    "section": "",
    "text": "title: ‚Äúabout‚Äù format: html ‚Äî\n\n\n\n\nThis repository provides a reproducible pipeline for processing and analyzing household data from the 2022 Demographic Census conducted by the Brazilian Institute of Geography and Statistics (IBGE). The data is aggregated at the census tract level, allowing for detailed spatial analysis of household characteristics across Brazil. This repository contains scripts, documentation, and visual outputs for the construction of census indicators aggregated at census tract level, based on the Brazilian Demographic Census (IBGE, 2022).\nThe project is organized into Data, Indicators, and Maps, and is published as a static website using Quarto + GitHub Pages.\nüîó Project website:\nhttps://tcshund.github.io/censo2022-domicilios"
  },
  {
    "objectID": "about.html#head",
    "href": "about.html#head",
    "title": "about",
    "section": "",
    "text": "title: ‚Äúabout‚Äù format: html ‚Äî\n\n\n\n\nThis repository provides a reproducible pipeline for processing and analyzing household data from the 2022 Demographic Census conducted by the Brazilian Institute of Geography and Statistics (IBGE). The data is aggregated at the census tract level, allowing for detailed spatial analysis of household characteristics across Brazil. This repository contains scripts, documentation, and visual outputs for the construction of census indicators aggregated at census tract level, based on the Brazilian Demographic Census (IBGE, 2022).\nThe project is organized into Data, Indicators, and Maps, and is published as a static website using Quarto + GitHub Pages.\nüîó Project website:\nhttps://tcshund.github.io/censo2022-domicilios"
  },
  {
    "objectID": "about.html#acknowledgments",
    "href": "about.html#acknowledgments",
    "title": "about",
    "section": "Acknowledgments",
    "text": "Acknowledgments\n\n\n\n\nThis work was developed with support from the Center for Metropolitan Studies (CEM) based at the School of Philosophy, Letters and Human Sciences (FFLCH) of the University of S√£o Paulo (USP) and at the Brazilian Center for Analysis and Planning (CEBRAP).\n\n\n\n\n\n\n\nThis study was financed, in part, by the S√£o Paulo Research Foundation (FAPESP), Brazil. Process Number 2013/07616-7."
  },
  {
    "objectID": "about.html#section",
    "href": "about.html#section",
    "title": "about",
    "section": "=======",
    "text": "=======\ntitle: ‚Äúabout‚Äù format: html ‚Äî\n\n\n\nHousing Census Data ‚Äì Brazil (IBGE 2022)\nThis repository provides a reproducible pipeline for processing and analyzing household data from the 2022 Demographic Census conducted by the Brazilian Institute of Geography and Statistics (IBGE). The data is aggregated at the census tract level, allowing for detailed spatial analysis of household characteristics across Brazil. This repository contains scripts, documentation, and visual outputs for the construction of census indicators aggregated at census tract level, based on the Brazilian Demographic Census (IBGE, 2022).\nThe project is organized into Data, Indicators, and Maps, and is published as a static website using Quarto + GitHub Pages.\nüîó Project website:\nhttps://tcshund.github.io/censo2022-domicilios"
  },
  {
    "objectID": "about.html#acknowledgments-1",
    "href": "about.html#acknowledgments-1",
    "title": "about",
    "section": "Acknowledgments",
    "text": "Acknowledgments\n\n\n\n\nThis work was developed with support from the Center for Metropolitan Studies (CEM) based at the School of Philosophy, Letters and Human Sciences (FFLCH) of the University of S√£o Paulo (USP) and at the Brazilian Center for Analysis and Planning (CEBRAP).\n\n\n\n\n\n\n\nThis study was financed, in part, by the S√£o Paulo Research Foundation (FAPESP), Brazil. Process Number 2013/07616-7.\n\n\n\n\n\n\n\n\n\n\nc8617cbb86bebf8f2dfead43291acfc8d5bec62b"
  }
]